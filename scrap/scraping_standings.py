"""
Scraping de posiciones/standings deportivos
==========================================

Este mÃ³dulo se encarga de descargar las tablas de posiciones de competiciones deportivas
desde la API de ScoresWay, organizando los archivos JSON por directorios
de competiciÃ³n y temporada.

Autor: Tu nombre
Fecha: Julio 2025
"""

import os
import json
import time
import random
import requests
import pandas as pd
from urllib.parse import quote
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from typing import Dict, List, Optional, Tuple, Union

# Importar funciones comunes
from utils_common import get_season_name_from_url, get_torneo_id, sanitize_dir_name


class StandingsScraper:
    """
    Clase para hacer scraping de standings/posiciones desde la API de ScoresWay.
    """
    
    def __init__(self, 
                 sdapi_outlet_key: str = 'ft1tiv1inq7v1sk3y9tv12yh5',
                 callback_id: str = 'W3e14cbc3e4b2577e854bf210e5a3c7028c7409678',
                 base_url: str = "https://www.scoresway.com",
                 data_dir: str = 'data'):
        """
        Inicializa el scraper de standings.
        
        Args:
            sdapi_outlet_key (str): Clave del outlet para la API
            callback_id (str): ID del callback para JSONP
            base_url (str): URL base del sitio web
            data_dir (str): Directorio base de datos
        """
        self.sdapi_outlet_key = sdapi_outlet_key
        self.callback_id = callback_id
        self.base_url = base_url
        self.api_base_url = "https://api.performfeeds.com/soccerdata/standings"
        self.data_dir = data_dir
        
        # Configurar headers
        self.headers = {
            'Accept': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Mobile Safari/537.36'
        }
        
        # Configurar sesiÃ³n con reintentos
        self.session = self._create_session_with_retries()
        
        # ConfiguraciÃ³n de delays
        self.min_delay = 1.0
        self.max_delay = 2.0
        
        # Contadores para estadÃ­sticas
        self.reset_stats()
    
    def _create_session_with_retries(self) -> requests.Session:
        """
        Crea una sesiÃ³n de requests con estrategia de reintentos.
        
        Returns:
            requests.Session: SesiÃ³n configurada
        """
        session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[500, 502, 503, 504, 429],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        return session
    
    def reset_stats(self) -> None:
        """Reinicia las estadÃ­sticas de descarga."""
        self.exitos = 0
        self.fallos = 0
        self.saltados = 0
        self.procesados = 0
    
    def set_api_credentials(self, sdapi_outlet_key: str, callback_id: str) -> None:
        """
        Actualiza las credenciales de la API.
        
        Args:
            sdapi_outlet_key (str): Nueva clave del outlet
            callback_id (str): Nuevo ID del callback
        """
        self.sdapi_outlet_key = sdapi_outlet_key
        self.callback_id = callback_id
        print(f"âœ… Credenciales de API actualizadas")
    
    def set_delay_range(self, min_delay: float, max_delay: float) -> None:
        """
        Configura el rango de delays entre requests.
        
        Args:
            min_delay (float): Delay mÃ­nimo en segundos
            max_delay (float): Delay mÃ¡ximo en segundos
        """
        self.min_delay = min_delay
        self.max_delay = max_delay
        print(f"â±ï¸  Delays configurados: {min_delay}-{max_delay} segundos")
    
    def obtener_standings_json(self, torneo_id: str, competicion_name: str, referer: str = None) -> Dict:
        """
        Obtiene los datos de standings desde la API.
        
        Args:
            torneo_id (str): ID del torneo
            competicion_name (str): Nombre de la competiciÃ³n
            referer (str): URL de referencia
            
        Returns:
            Dict: Datos de standings en formato JSON
            
        Raises:
            Exception: Si hay error en la peticiÃ³n o parsing
        """
        try:
            # Configurar referer
            if not referer:
                referer_base = f'{self.base_url}/en_GB/soccer/'
                safe_competition_name = quote(competicion_name)
                referer = f"{referer_base}{safe_competition_name}/{torneo_id}/fixtures"
            
            # Construir URL de la API
            standings_url = (
                f"{self.api_base_url}/{self.sdapi_outlet_key}/"
                f"?_rt=c&tmcl={torneo_id}&live=yes&_lcl=en&_fmt=jsonp"
                f"&sps=widgets&_clbk={self.callback_id}"
            )
            
            # Actualizar headers con referer
            headers = self.headers.copy()
            headers['Referer'] = referer
            
            print(f"ğŸ† API URL: {standings_url}")
            
            # Realizar peticiÃ³n
            response = self.session.get(standings_url, headers=headers)
            response.raise_for_status()
            
            # Limpiar JSONP y extraer JSON puro
            content = response.text
            json_start = content.find('(') + 1
            json_end = content.rfind(')')
            
            if json_start <= 0 or json_end <= json_start:
                raise Exception("No se pudo extraer JSON del response JSONP")
            
            standings_data = json.loads(content[json_start:json_end])
            
            return standings_data
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Error al realizar peticiÃ³n: {e}")
        except json.JSONDecodeError as e:
            raise Exception(f"Error al parsear JSON: {e}")
        except Exception as e:
            raise Exception(f"Error inesperado: {e}")
    
    def save_standings_json(self, season_row: pd.Series, skip_existing: bool = True) -> bool:
        """
        Descarga y guarda el standings JSON para una temporada.
        
        Args:
            season_row (pd.Series): Fila del DataFrame de temporadas
            skip_existing (bool): Si saltar archivos que ya existen
            
        Returns:
            bool: True si se guardÃ³ exitosamente, False en caso contrario
        """
        try:
            # Obtener ID del torneo
            torneo_id = get_torneo_id(season_row['url_temporada'])
            if not torneo_id:
                print(f"âš ï¸  No se pudo extraer torneo_id de: {season_row['url_temporada']}")
                return False
            
            # Obtener nombre de temporada
            season_name = get_season_name_from_url(season_row['url_resultados'])
            if not season_name:
                print(f"âš ï¸  No se pudo extraer season_name de: {season_row['url_resultados']}")
                return False
            
            # Crear nombres de directorio seguros
            continente_dir = sanitize_dir_name(season_row['continente'])
            pais_dir = sanitize_dir_name(season_row['pais'])
            competicion = sanitize_dir_name(season_row['competicion'])
            competicion_dir = f"{competicion}_{season_row['id_competicion']}"
            
            # Construir ruta del directorio
            dir_path = os.path.join(
                self.data_dir,
                continente_dir,
                pais_dir,
                competicion_dir,
                season_name
            )
            
            # Verificar si el directorio existe
            if not os.path.exists(dir_path):
                print(f"âš ï¸  Directorio no existe: {dir_path}")
                return False
            
            # Ruta del archivo JSON
            json_path = os.path.join(dir_path, 'standings.json')
            
            # Si el archivo ya existe y skip_existing es True, saltarlo
            if skip_existing and os.path.exists(json_path):
                print(f"â­ï¸  Archivo ya existe (saltando): {json_path}")
                self.saltados += 1
                return True
            
            # Obtener datos de standings
            standings_data = self.obtener_standings_json(
                torneo_id=torneo_id,
                competicion_name=competicion,
                referer=season_row['url_temporada']
            )
            
            # Guardar el JSON
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(standings_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Standings guardado: {json_path}")
            self.exitos += 1
            
            # Delay entre peticiones
            delay = random.uniform(self.min_delay, self.max_delay)
            time.sleep(delay)
            
            return True
            
        except Exception as e:
            print(f"âŒ Error al procesar {season_row.get('temporada', 'N/A')}: {str(e)}")
            self.fallos += 1
            return False
    
    def process_seasons(self, 
                       df_seasons: pd.DataFrame,
                       filters: Optional[Dict] = None,
                       skip_existing: bool = True,
                       start_index: int = 0,
                       limit: Optional[int] = None) -> Dict:
        """
        Procesa mÃºltiples temporadas para descargar standings.
        
        Args:
            df_seasons (pd.DataFrame): DataFrame con temporadas
            filters (Dict, optional): Filtros para aplicar (continente, pais, competicion)
            skip_existing (bool): Si saltar archivos existentes
            start_index (int): Ãndice de inicio
            limit (Optional[int]): LÃ­mite de temporadas a procesar
            
        Returns:
            Dict: EstadÃ­sticas del procesamiento
        """
        try:
            # Reiniciar estadÃ­sticas
            self.reset_stats()
            start_time = time.time()
            
            # Aplicar filtros si se proporcionan
            df_filtered = self._apply_filters(df_seasons, filters)
            
            # Determinar rango de procesamiento
            end_index = len(df_filtered)
            if limit:
                end_index = min(start_index + limit, end_index)
            
            df_to_process = df_filtered.iloc[start_index:end_index]
            
            print(f"ğŸš€ Iniciando descarga de standings...")
            print(f"   - Temporadas originales: {len(df_seasons)}")
            if filters:
                print(f"   - Temporadas despuÃ©s de filtros: {len(df_filtered)}")
            print(f"   - Temporadas a procesar: {len(df_to_process)}")
            print(f"   - Rango: {start_index} a {end_index-1}")
            print(f"   - Delay: {self.min_delay}-{self.max_delay} segundos")
            
            # Procesar cada temporada
            for idx, (_, row) in enumerate(df_to_process.iterrows()):
                try:
                    competition_info = f"{row.get('competicion', 'N/A')} - {row.get('temporada', 'N/A')}"
                    print(f"\nğŸ“‹ Procesando {idx + 1}/{len(df_to_process)}: {competition_info}")
                    
                    # Intentar guardar standings
                    self.save_standings_json(row, skip_existing)
                    self.procesados += 1
                    
                    # Mostrar progreso cada 10 elementos
                    if (idx + 1) % 10 == 0:
                        self._print_progress(idx + 1, len(df_to_process), start_time)
                
                except KeyboardInterrupt:
                    print(f"\nâš ï¸  Procesamiento interrumpido por el usuario")
                    break
                except Exception as e:
                    print(f"âŒ Error inesperado en temporada {idx}: {e}")
                    self.fallos += 1
                    self.procesados += 1
            
            # Calcular tiempo total
            duration = time.time() - start_time
            
            # Crear estadÃ­sticas finales
            stats = {
                'total_seasons': len(df_to_process),
                'procesados': self.procesados,
                'exitosos': self.exitos,
                'saltados': self.saltados,
                'fallos': self.fallos,
                'duration': duration,
                'temporadas_por_minuto': (self.procesados / (duration / 60)) if duration > 0 else 0
            }
            
            # Imprimir resumen final
            self._print_final_summary(stats)
            
            return stats
            
        except Exception as e:
            print(f"âŒ Error en procesamiento: {e}")
            raise
    
    def _apply_filters(self, df: pd.DataFrame, filters: Optional[Dict]) -> pd.DataFrame:
        """
        Aplica filtros al DataFrame de temporadas.
        
        Args:
            df (pd.DataFrame): DataFrame original
            filters (Dict, optional): Filtros a aplicar
            
        Returns:
            pd.DataFrame: DataFrame filtrado
        """
        if not filters:
            return df
        
        df_filtered = df.copy()
        
        for column, value in filters.items():
            if column in df_filtered.columns:
                if isinstance(value, list):
                    df_filtered = df_filtered[df_filtered[column].isin(value)]
                else:
                    df_filtered = df_filtered[df_filtered[column] == value]
                print(f"ğŸ” Filtro aplicado - {column}: {value} â†’ {len(df_filtered)} temporadas")
        
        return df_filtered
    
    def _print_progress(self, current: int, total: int, start_time: float) -> None:
        """
        Imprime el progreso del procesamiento.
        """
        elapsed = time.time() - start_time
        rate = self.procesados / (elapsed / 60) if elapsed > 0 else 0
        
        print(f"\nğŸ“Š Progreso: {current}/{total} ({current/total*100:.1f}%)")
        print(f"   âš¡ Velocidad: {rate:.2f} temporadas/minuto")
        print(f"   âœ… Exitosas: {self.exitos}")
        print(f"   â­ï¸  Saltadas: {self.saltados}")
        print(f"   âŒ Errores: {self.fallos}")
        
        if elapsed > 0:
            remaining = (total - current) * (elapsed / current)
            print(f"   â° Tiempo estimado restante: {remaining/60:.1f} minutos")
    
    def _print_final_summary(self, stats: Dict) -> None:
        """
        Imprime el resumen final del procesamiento.
        """
        print(f"\n" + "="*60)
        print(f"ğŸ† RESUMEN FINAL - DESCARGA DE STANDINGS")
        print(f"="*60)
        print(f"â° Tiempo total: {stats['duration']:.1f} segundos ({stats['duration']/60:.1f} minutos)")
        print(f"ğŸ“‹ Temporadas procesadas: {stats['procesados']}/{stats['total_seasons']}")
        print(f"âœ… Descargas exitosas: {stats['exitosos']}")
        print(f"â­ï¸  Archivos saltados (ya existÃ­an): {stats['saltados']}")
        print(f"âŒ Fallos: {stats['fallos']}")
        print(f"âš¡ Velocidad promedio: {stats['temporadas_por_minuto']:.2f} temporadas/minuto")
        
        if stats['exitosos'] > 0:
            success_rate = (stats['exitosos'] / stats['procesados']) * 100
            print(f"ğŸ“ˆ Tasa de Ã©xito: {success_rate:.1f}%")


def find_standings_resume_index(df_seasons: pd.DataFrame, filters: Optional[Dict] = None) -> int:
    """
    Encuentra el Ã­ndice desde donde continuar basÃ¡ndose en standings ya descargados.
    
    Args:
        df_seasons (pd.DataFrame): DataFrame con temporadas
        filters (Dict, optional): Filtros aplicados
        
    Returns:
        int: Ãndice desde donde continuar
    """
    try:
        scraper = StandingsScraper()
        
        # Aplicar filtros si se proporcionan
        df_filtered = scraper._apply_filters(df_seasons, filters) if filters else df_seasons
        
        # Revisar quÃ© standings ya existen
        for idx, row in df_filtered.iterrows():
            try:
                # Obtener nombre de temporada
                season_name = get_season_name_from_url(row['url_resultados'])
                if not season_name:
                    continue
                
                # Crear nombres de directorio seguros
                continente_dir = sanitize_dir_name(row['continente'])
                pais_dir = sanitize_dir_name(row['pais'])
                competicion = sanitize_dir_name(row['competicion'])
                competicion_dir = f"{competicion}_{row['id_competicion']}"
                
                # Construir ruta del archivo
                dir_path = os.path.join(
                    'data',
                    continente_dir,
                    pais_dir,
                    competicion_dir,
                    season_name
                )
                json_path = os.path.join(dir_path, 'standings.json')
                
                if not os.path.exists(json_path):
                    print(f"ğŸ” Primer standings faltante encontrado en Ã­ndice {idx}")
                    print(f"   CompeticiÃ³n: {row.get('competicion', 'N/A')}")
                    print(f"   Temporada: {row.get('temporada', 'N/A')}")
                    print(f"   PaÃ­s: {row.get('pais', 'N/A')}")
                    return idx
                    
            except Exception as e:
                # Si hay error al construir la ruta, significa que falta
                print(f"âš ï¸  Error procesando temporada {idx}: {e}")
                return idx
        
        print("âœ… Todos los standings ya fueron descargados")
        return len(df_filtered)
        
    except Exception as e:
        print(f"âš ï¸  Error al buscar punto de reanudaciÃ³n: {e}")
        return 0


# Funciones de conveniencia para usar directamente
def download_standings_by_filters(df_seasons: pd.DataFrame,
                                 continente: Optional[str] = None,
                                 pais: Optional[str] = None,
                                 competicion: Optional[str] = None,
                                 skip_existing: bool = True,
                                 start_index: int = 0,
                                 limit: Optional[int] = None,
                                 **scraper_kwargs) -> Dict:
    """
    Descarga standings aplicando filtros comunes.
    
    Args:
        df_seasons (pd.DataFrame): DataFrame con temporadas
        continente (str, optional): Filtrar por continente
        pais (str, optional): Filtrar por paÃ­s
        competicion (str, optional): Filtrar por competiciÃ³n
        skip_existing (bool): Si saltar archivos existentes
        start_index (int): Ãndice de inicio para procesar
        limit (Optional[int]): LÃ­mite de temporadas a procesar
        **scraper_kwargs: Argumentos adicionales para StandingsScraper
        
    Returns:
        Dict: EstadÃ­sticas del procesamiento
    """
    # Crear filtros
    filters = {}
    if continente:
        filters['continente'] = continente
    if pais:
        filters['pais'] = pais
    if competicion:
        filters['competicion'] = competicion
    
    # Crear scraper con argumentos apropiados
    scraper = StandingsScraper(**scraper_kwargs)
    
    # Procesar con todos los parÃ¡metros
    return scraper.process_seasons(
        df_seasons, 
        filters=filters, 
        skip_existing=skip_existing,
        start_index=start_index,
        limit=limit
    )


def smart_download_standings(df_seasons: pd.DataFrame,
                            continente: Optional[str] = None,
                            pais: Optional[str] = None,
                            competicion: Optional[str] = None,
                            restart_from_zero: bool = False,
                            batch_size: int = 100,
                            **scraper_kwargs) -> Dict:
    """
    FunciÃ³n inteligente que detecta automÃ¡ticamente desde dÃ³nde continuar la descarga de standings.
    
    Args:
        df_seasons (pd.DataFrame): DataFrame con temporadas
        continente (str, optional): Filtrar por continente
        pais (str, optional): Filtrar por paÃ­s
        competicion (str, optional): Filtrar por competiciÃ³n
        restart_from_zero (bool): Si True, borra standings existentes y empieza de cero
        batch_size (int): NÃºmero de temporadas a procesar en este lote
        **scraper_kwargs: Argumentos adicionales para StandingsScraper
        
    Returns:
        Dict: EstadÃ­sticas del procesamiento
        
    Example:
        # Para empezar de cero:
        stats = smart_download_standings(df_seasons, pais='Argentina', restart_from_zero=True)
        
        # Para continuar automÃ¡ticamente:
        stats = smart_download_standings(df_seasons, pais='Argentina', restart_from_zero=False)
    """
    # Crear filtros
    filters = {}
    if continente:
        filters['continente'] = continente
    if pais:
        filters['pais'] = pais
    if competicion:
        filters['competicion'] = competicion
    
    # Aplicar filtros para obtener subconjunto
    scraper = StandingsScraper(**scraper_kwargs)
    df_filtered = scraper._apply_filters(df_seasons, filters) if filters else df_seasons
    
    print(f"ğŸ¯ Filtros aplicados: {filters if filters else 'Ninguno'}")
    print(f"ğŸ“‹ Temporadas a procesar: {len(df_filtered)}")
    
    # Si restart_from_zero, borrar archivos existentes
    if restart_from_zero:
        deleted_count = 0
        print("ğŸ”¥ Modo reinicio: Borrando standings existentes...")
        
        for _, row in df_filtered.iterrows():
            try:
                # Obtener nombre de temporada
                season_name = get_season_name_from_url(row['url_resultados'])
                if not season_name:
                    continue
                
                # Crear nombres de directorio seguros
                continente_dir = sanitize_dir_name(row['continente'])
                pais_dir = sanitize_dir_name(row['pais'])
                competicion_clean = sanitize_dir_name(row['competicion'])
                competicion_dir = f"{competicion_clean}_{row['id_competicion']}"
                
                # Construir ruta del archivo
                dir_path = os.path.join(
                    'data',
                    continente_dir,
                    pais_dir,
                    competicion_dir,
                    season_name
                )
                json_path = os.path.join(dir_path, 'standings.json')
                
                if os.path.exists(json_path):
                    os.remove(json_path)
                    deleted_count += 1
                    
            except Exception as e:
                print(f"âš ï¸  Error borrando archivo: {e}")
        
        print(f"ğŸ—‘ï¸  Eliminados {deleted_count} standings existentes")
        start_index = 0
    else:
        # Encontrar desde dÃ³nde continuar
        start_index = find_standings_resume_index(df_seasons, filters)
        
        if start_index >= len(df_filtered):
            print("âœ… Todos los standings ya estÃ¡n descargados")
            return {
                'total_seasons': len(df_filtered),
                'procesados': len(df_filtered),
                'exitosos': len(df_filtered),
                'saltados': len(df_filtered),
                'fallos': 0,
                'duration': 0,
                'temporadas_por_minuto': 0
            }
    
    print(f"ğŸš€ Empezando descarga desde temporada {start_index + 1}/{len(df_filtered)}")
    
    # Procesar standings
    return scraper.process_seasons(
        df_seasons,
        filters=filters,
        skip_existing=not restart_from_zero,
        start_index=start_index,
        limit=batch_size
    )


# FunciÃ³n de testing
def test_standings_scraper():
    """
    FunciÃ³n de prueba para el scraper de standings.
    """
    print("=== Testing Standings Scraper ===")
    
    try:
        # Cargar temporadas existentes
        from scraping_seasons import load_existing_seasons
        
        df_seasons = load_existing_seasons()
        print(f"ğŸ“‹ Temporadas cargadas: {len(df_seasons)}")
        
        # Probar con Argentina (solo primeras 2 temporadas)
        stats = download_standings_by_filters(
            df_seasons,
            pais='Argentina',
            skip_existing=True,
            limit=2
        )
        
        print(f"\nğŸ“Š Resultado del test:")
        print(f"   - Procesadas: {stats['procesados']}")
        print(f"   - Exitosas: {stats['exitosos']}")
        print(f"   - Errores: {stats['fallos']}")
        
        return stats['fallos'] == 0
        
    except Exception as e:
        print(f"âŒ Error en testing: {e}")
        return False


if __name__ == "__main__":
    test_standings_scraper()